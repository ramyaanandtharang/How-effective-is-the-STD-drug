{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import gc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('F:/hackthons/Hacker earth/Effectiveness of STD drug/train.csv')\n",
    "test=pd.read_csv('F:/hackthons/Hacker earth/Effectiveness of STD drug/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id name_of_drug             use_case_for_drug  \\\n",
       "0      206461    Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260   Guanfacine                          ADHD   \n",
       "2       92703       Lybrel                 Birth Control   \n",
       "\n",
       "                                   review_by_patient  effectiveness_rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...                     9   \n",
       "1  \"My son is halfway through his fourth week of ...                     8   \n",
       "2  \"I used to take another oral contraceptive, wh...                     5   \n",
       "\n",
       "  drug_approved_by_UIC  number_of_times_prescribed  base_score  \n",
       "0            20-May-12                          27    8.022969  \n",
       "1            27-Apr-10                         192    7.858458  \n",
       "2            14-Dec-09                          17    6.341969  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Sentiment Intensity to Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "train = train.join(train['review_by_patient'].apply(lambda x: analyzer.polarity_scores(x)).apply(pd.Series))\n",
    "test = test.join(test['review_by_patient'].apply(lambda x: analyzer.polarity_scores(x)).apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=text.lower() \n",
    "    text=re.sub(r\"\\d+\",\"\",text) \n",
    "    text=text.translate(str.maketrans(\"\",\"\",string.punctuation))  \n",
    "    text=re.sub('\\s+',' ',text)  \n",
    "    text=[token for token in text.split() if len(token)>2]   \n",
    "    text=' '.join(text)\n",
    "    shortword=re.compile(r'\\W*\\b\\w{10,}\\b')   \n",
    "    text=shortword.sub('',text)\n",
    "    stop_words=set(stopwords.words('english')) \n",
    "    tokens=word_tokenize(text)\n",
    "    ps=PorterStemmer()\n",
    "    \n",
    "    text=''.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cleaned_Text'] = train['review_by_patient'].apply(clean_text)\n",
    "test['Cleaned_Text'] = test['review_by_patient'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = set(stopwords.words('english'))\n",
    "def convert(words) :\n",
    "  \n",
    "    current_words = []\n",
    "    stop_words=set(stopwords.words('english')) \n",
    "    for i in words :\n",
    "        if i not in stopword :\n",
    "            \n",
    "            updated_word = ps.stem(i)\n",
    "            current_words.append(updated_word.lower())\n",
    "    return current_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = train['drug_approved_by_UIC'].str.split(\"-\", n = 2, expand = True) \n",
    "train['Day'] = new[0]\n",
    "train['Month'] = new[1]\n",
    "train['Year'] = new[2]\n",
    "del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = test['drug_approved_by_UIC'].str.split(\"-\", n = 2, expand = True) \n",
    "test['Day'] = new[0]\n",
    "test['Month'] = new[1]\n",
    "test['Year'] = new[2]\n",
    "del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Drug'] = train['name_of_drug']\n",
    "train['Drug'] = train['Drug'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Drug'] = test['name_of_drug']\n",
    "test['Drug'] = test['Drug'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'name_of_drug', 'use_case_for_drug', 'review_by_patient',\n",
       "       'effectiveness_rating', 'drug_approved_by_UIC',\n",
       "       'number_of_times_prescribed', 'base_score', 'neg', 'neu', 'pos',\n",
       "       'compound', 'Cleaned_Text', 'lemma', 'Day', 'Month', 'Year', 'Drug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'name_of_drug', 'review_by_patient',\n",
       "       'drug_approved_by_UIC', 'number_of_times_prescribed',\n",
       "       'use_case_for_drug', 'effectiveness_rating', 'neg', 'neu', 'pos',\n",
       "       'compound', 'Cleaned_Text', 'lemma', 'Day', 'Month', 'Year', 'Drug'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Drugs_Eff_Rating = pd.DataFrame()\n",
    "Train_Drugs_Eff_Rating['Drug'] = train['Drug']\n",
    "Train_Drugs_Eff_Rating['Year'] = train['Year']\n",
    "Train_Drugs_Eff_Rating['Avg_Rating'] = train['effectiveness_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Drugs_Eff_Rating = pd.DataFrame()\n",
    "Test_Drugs_Eff_Rating['Drug'] = test['Drug']\n",
    "Test_Drugs_Eff_Rating['Year'] = test['Year']\n",
    "Test_Drugs_Eff_Rating['Avg_Rating'] = test['effectiveness_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Drugs_Eff_Rating = Train_Drugs_Eff_Rating.groupby(['Drug', 'Year'])['Avg_Rating'].mean().round(2)\n",
    "Train_Drugs_Eff_Rating = Train_Drugs_Eff_Rating.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Drugs_Eff_Rating = Test_Drugs_Eff_Rating.groupby(['Drug', 'Year'])['Avg_Rating'].mean().round(2)\n",
    "Test_Drugs_Eff_Rating = Test_Drugs_Eff_Rating.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, Train_Drugs_Eff_Rating, on = (['Drug', 'Year']), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, Test_Drugs_Eff_Rating, on = (['Drug', 'Year']), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Patient_Id = test['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'name_of_drug', 'use_case_for_drug', 'review_by_patient',\n",
       "       'effectiveness_rating', 'drug_approved_by_UIC',\n",
       "       'number_of_times_prescribed', 'base_score', 'neg', 'neu', 'pos',\n",
       "       'compound', 'Cleaned_Text', 'lemma', 'Day', 'Month', 'Year', 'Drug',\n",
       "       'Avg_Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'name_of_drug', 'review_by_patient',\n",
       "       'drug_approved_by_UIC', 'number_of_times_prescribed',\n",
       "       'use_case_for_drug', 'effectiveness_rating', 'neg', 'neu', 'pos',\n",
       "       'compound', 'Cleaned_Text', 'lemma', 'Day', 'Month', 'Year', 'Drug',\n",
       "       'Avg_Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['patient_id', 'name_of_drug', 'use_case_for_drug', 'review_by_patient',\n",
    "            'drug_approved_by_UIC', 'Drug'], axis =1, inplace = True)\n",
    "test.drop(['patient_id', 'name_of_drug', 'use_case_for_drug', 'review_by_patient',\n",
    "           'drug_approved_by_UIC', 'Drug'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['effectiveness_rating', 'number_of_times_prescribed', 'base_score',\n",
       "       'neg', 'neu', 'pos', 'compound', 'Cleaned_Text', 'lemma', 'Day',\n",
       "       'Month', 'Year', 'Avg_Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_times_prescribed', 'effectiveness_rating', 'neg', 'neu',\n",
       "       'pos', 'compound', 'Cleaned_Text', 'lemma', 'Day', 'Month', 'Year',\n",
       "       'Avg_Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', stop_words='english', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', \n",
    "                             ngram_range=(1,2), max_df=0.9, min_df=0.01, max_features=None, \n",
    "                             binary=False, norm='l2', use_idf=1, smooth_idf=1, sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf_vect.transform(train['Cleaned_Text'])\n",
    "test_tfidf = tfidf_vect.transform(test['Cleaned_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32165, 549), (32165, 12))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_tfidf.toarray(),columns=tfidf_vect.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_tfidf.toarray(),columns=tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['base_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "#rmse = sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "def rmsle(y_true, y_pred):\n",
    "    return 100*max(0,1-sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['effectiveness_rating'] = train['effectiveness_rating']\n",
    "train_df['number_of_times_prescribed'] = train['number_of_times_prescribed']\n",
    "train_df['Pos_Score'] = train['pos']\n",
    "train_df['Neg_Score'] = train['neg']\n",
    "train_df['Neu_Score'] = train['neu']\n",
    "train_df['compound'] = train['compound']\n",
    "train_df['Avg_Rating'] = train['Avg_Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['effectiveness_rating'] = test['effectiveness_rating']\n",
    "test_df['number_of_times_prescribed'] = test['number_of_times_prescribed']\n",
    "test_df['Pos_Score'] = test['pos']\n",
    "test_df['Neg_Score'] = test['neg']\n",
    "test_df['Neu_Score'] = test['neu']\n",
    "test_df['compound'] = test['compound']\n",
    "test_df['Avg_Rating'] = test['Avg_Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32165, 556), (10760, 556))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(train_df, target, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25732, 556), (6433, 556))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\3.7\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:27:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.9, gamma=1,\n",
       "             importance_type='gain', learning_rate=0.001, max_delta_step=0,\n",
       "             max_depth=22, min_child_weight=1, missing=None, n_estimators=1800,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=0.9, verbosity=1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBRegressor(objective ='reg:linear', n_estimators=1800, learning_rate=0.001, gamma=0, subsample=0.9,\n",
    "                           colsample_bytree=0.9, max_depth=22)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_tpred = xgb.predict(X_train)\n",
    "xgb_y_pred = xgb.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse of prediction is: 0\n",
      "Test rmse of prediction is: 0\n"
     ]
    }
   ],
   "source": [
    "print('Train rmse of prediction is:', rmsle(y_train, xgb_y_tpred))\n",
    "print('Test rmse of prediction is:', rmsle(y_cv, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_XGB = xgb.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame()\n",
    "Submission['patient_id'] = Test_Patient_Id\n",
    "Submission['base_score'] = Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.to_csv('STD_Preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10760, 2), (10760, 603))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
